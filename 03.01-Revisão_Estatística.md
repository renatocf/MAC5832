Revisão Estatística
====================

Variáveis Aleatórias Multivariadas
-----------------------------------

- Mais de uma VA sobre um mesmo espaço Ω → VA multivariada
  (ou vetor aleatório)

- Reconhecimento estatístico de padrões
  - **Padrão** é um conjundo de VAs (ou d *características*)
  - Conjunto de VAs => **vetor de características**
  - Padrão = um **ponto no espaço ℝ^d**
  - Todas as possíveis realizações do vetor de características:
    **espaço de características**

  - O **reconhecmento estatístico de padrões** pressupõe que há uma
    distribuição de probabilidade associada ao espaço de características.

- Podemo pensar em uma variável de várias dimensões, ou v.a. multivariada.

  - Normal univariada N(µ, σ²):
    `p(x) = 1/√(2πσ) * e^{ -1/2*(x-µ/σ)²}`

  - Normal multivariada:
    `p(x) = 1/(2π^d/2 * |Σ|^1/2) * e^{ -1/2*(x-µ)^t Σ^-1(x-µ)}`

    ```
    Σ = (σ_ij)^d_{i,j=1}} : matriz de covariâncai
    σ_ii = E[(x_i-µ_i)²] : variância de x_i
    σ_ij = E[(x_i-µ_i)(x_j-µ_j)], i ≠ j: covariância de x_i e x_j
    ```

  - Se **x** = `(x1, x2, ..., xd)` uma **variável aleatória multidimensional**.

  - **Matriz de variância**:
    
    ```
      [  σ1   σ12  σ13  ]
      [  σ21  σ2   σ23  ]
      [  σ31  σ31  σ3   ]
    ```

  - **Vetor de médias**: `µ = E(x) = (µ_1, µ_2, ..., µd)`

  -  **Correlação** (entre componentes xi e xj): `ρij = σij/√σi√σj`

  - **Matriz de correlação**:

    ```
      [   1   ρ12  ρ13  ]
      [  ρ21   1   ρ23  ]
      [  ρ31  ρ31   1   ]
    ```

- Exemplo:

  ```
  X = { [0][0][1][1][2] }
      { [0][1][2][3][4] }

  Média: = 1/5 ( [0][0][1][1][2] ) = 1/5 * [ 4] = [0.8]
               ( [0][1][2][3][4] )         [10]   [  2]

  5S = ([0] - [0.8])*([0 0] - [0.8 2]) + ...
       ([0]   [  2])
  ```

Propriedades da matriz de covariância
--------------------------------------

- A matrix de covariância Σ é uma matriz **simétrica** e **positivo
  semi-definica** (x^TΣx > 0, ∀x ≠ 0).

- Todos os auto-valores de matrizes simétricas são reais.

- Os auto-vetores correspondentes a auto-valores distintos são **ortogonais**.

- A é **positivo definida** se x^TAx > 0, para todo x ≠ 0.

- Todos os **auto-valores de matrizes definidas positivas** são **reais e
  positivos**.

- Isto significa que a matriz de covariância possui as propriedades que
  garantem a existência dos auto-vetores, e portanteo ela é diagonalizável.

- Dada uma matriz de covariância Σ, os seus **auto-vetores correspondem aos
  componentes principais**: a direção do auto-vetor principal corresponde ao de
  maior dispersão dos dados.
  ```
                    ^
                    |                  .. ^..
                    |                .. ./.. ..  
                    |              . . ./.... .   
                    |            . ... /... ..
                    |           . <---*  ..  
                    |         .. . .... ..
                    |          .. . ..  
                    |
                    +--------------------------------->
  ```

- Esses auto-valores/vetores indicam as direções (2 a 2 ortogonais) de maior
  dispersão dos dados. Quanto maior o auto-vetor, maior a dispersão na
  respectiva direção.

- Mais do que isso, o conjunto de todos os pontos x que satisfazem a igualdade:
  x^tΣx = c² forma uma elipsóide.

- Pode-se mostrar que esse elipsóide tem eixos: `±x*1/√λi e_i`.
